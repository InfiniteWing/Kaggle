{
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "_cell_guid": "8aa132e3-5e23-4416-98c2-44042575ba1f",
        "collapsed": false,
        "_uuid": "c72bb1de9324692d619c53e23250862245d816f5",
        "_execution_state": "idle"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# **Simple way to do the validation**\n### *InfiniteWing*\n### *2017-07-30*\n\nHello, this notebook will demonstrate a simple way to do local validation. There's a similar post [Validation demo](https://www.kaggle.com/happycube/validation-demo-325-cv-3276-lb), you can also take a look on it.",
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "_cell_guid": "0b03285b-8b0c-4712-aa0c-1165e8d14db9",
        "collapsed": false,
        "_uuid": "608b449cfabc73d34408b2272b5c8cb454a068bd",
        "_execution_state": "idle"
      },
      "execution_count": null,
      "outputs": [],
      "source": "## Why validation\nI think it's a common question, for the most important reason is to avoid [overfitting](https://en.wikipedia.org/wiki/Overfitting). And also you can test your model and tuning parameters since their's a submission limit on Kaggle.\n\n## Create validation files\nBefore this step, I suggest you to take a look on some EDA notebooks. It will help you to understand the competition and data structure more quickly. \n\nOn my validation approach, I will change some 'train' label to 'valid' label in orders.csv. It is an in intuitive way and it's easy to run baseline kernel when you do validation.",
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "_cell_guid": "9f853f30-0fcc-48c1-a2a4-2dc2f5d1db74",
        "_uuid": "96204762a96358e83fdd9e3e1c2b7da1807813c7",
        "_execution_state": "idle",
        "trusted": false
      },
      "execution_count": 4,
      "outputs": [],
      "source": "import random\n\nrandom.seed(3228)\nnfold=2\n\n#read orders\nfr = open(\"../input/orders.csv\", 'r')\nfr.readline()# skip header\nlines=fr.readlines()\nvalid_order_ids=[[] for i in range(nfold)]\nprint(\"Total {} lines in orders.csv\".format(len(lines)))\n\nfold_csvs=[]\nfor fold in range(nfold):\n    outcsv = open(\"orders_valid_{}.csv\".format(fold), 'w')\n    outcsv.writelines(\"order_id,user_id,eval_set,order_number,order_dow,order_hour_of_day,days_since_prior_order\"+\"\\n\")\n    fold_csvs.append(outcsv)\n\nfor i,line in enumerate(lines):\n    datas=line.replace(\"\\n\",\"\").split(\",\")\n    order_id=datas[0]\n    eval_set=datas[2]\n    if(eval_set=='train'):\n        randNum=random.randint(1,1000)\n        for j in range(nfold):\n            if(randNum<=(j+1)*1000/(nfold) and randNum>(j)*1000/(nfold)):\n                valid_order_ids[j].append(order_id)\n                datas[2]='valid'\n                outline=','.join(datas)\n                fold_csvs[j].writelines(outline+\"\\n\")\n            else:\n                outline=','.join(datas)\n                fold_csvs[j].writelines(outline+\"\\n\")\n        \n    else:\n        outline=','.join(datas)\n        for j in range(nfold):\n            fold_csvs[j].writelines(outline+\"\\n\")",
      "cell_type": "code"
    },
    {
      "metadata": {
        "_cell_guid": "a58aeac4-6a0b-4a64-a832-c85a74dd134f",
        "collapsed": false,
        "_uuid": "c422732ed94c68304492ebc7e8a97883de41f261",
        "_execution_state": "idle"
      },
      "execution_count": null,
      "outputs": [],
      "source": "## Create True label for each validation file\nOnce you want to calculate the score, you need to have the ground truth label. We only need to read 'order_products__train.csv' because the 'valid' order is transformed from 'train' order.",
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "_cell_guid": "771c24c8-370e-414b-b4ba-59aa09f6a921",
        "collapsed": false,
        "_uuid": "528d06d4350b33e4b4cfa1035e64d1c4c8ac824c",
        "_execution_state": "idle",
        "trusted": false
      },
      "execution_count": 5,
      "outputs": [],
      "source": "orders={}         \n#read train orders\nfr = open(\"../input/order_products__train.csv\", 'r')\nfr.readline()# skip header\nlines=fr.readlines()\nfor i,line in enumerate(lines):\n    datas=line.replace(\"\\n\",\"\").split(\",\")\n    order_id=datas[0]\n    product_id=datas[1]\n    reorderer=int(datas[3])\n    if(order_id not in orders):\n        orders[order_id]=[]\n    if(reorderer==1):\n        orders[order_id].append(product_id)\n\nfor fold in range(nfold):\n    outcsv = open(\"orders_valid_label_{}.csv\".format(fold), 'w')\n    outcsv.writelines(\"order_id,label\"+\"\\n\")\n    for order_id in valid_order_ids[fold]:\n        if(len(orders[order_id])==0):\n            orders[order_id].append('None')\n        datas=[order_id,' '.join(orders[order_id])]\n        outcsv.writelines(','.join(datas)+\"\\n\")",
      "cell_type": "code"
    },
    {
      "metadata": {
        "_cell_guid": "e4adf3e4-d377-4543-9901-1f2793b99fcc",
        "collapsed": false,
        "_uuid": "daed9d84f6eb53f39813fc8ab0c95055dc938355",
        "_execution_state": "idle"
      },
      "execution_count": null,
      "outputs": [],
      "source": "# Calculate F1 score\nYou can use the following code to calculate F1 score for your validation prediction. It's easy to implement on baseline kernels. All you need is to predict on 'valid' orders rather than 'test' orders.\nI will demo it by using all Banana ( product_id = 24852 ) as predicts.",
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "_cell_guid": "beaf8101-a895-4d0b-8823-d9da53a474ac",
        "collapsed": false,
        "_uuid": "03137c74ac94380721fac30d9d5a4f4a6029183d",
        "_execution_state": "idle",
        "trusted": false
      },
      "execution_count": 7,
      "outputs": [],
      "source": "from sklearn.metrics import f1_score        \nfor fold in range(nfold):\n    f1_scores=[]\n    for order_id in valid_order_ids[fold]:\n        y_pred_labels=['24852'] # Use Banana as predict, you must replace it with your own prediction\n        y_true_labels=orders[order_id]\n        labels=list(set(y_pred_labels)|set(y_true_labels))\n        \n        y_pred=[]\n        y_true=[]\n        for label in labels:\n            if(label in y_true_labels):\n                y_true.append(1)\n            else:\n                y_true.append(0)\n            if(label in y_pred_labels):\n                y_pred.append(1)\n            else:\n                y_pred.append(0)\n        score=f1_score(y_true, y_pred)\n        f1_scores.append(score)\n    print(\"F1 Score = {} for all Banana's prediction\".format(sum(f1_scores)/len(f1_scores)))",
      "cell_type": "code"
    },
    {
      "metadata": {
        "_cell_guid": "2933b029-ffe4-41d5-b4ab-09118c487510",
        "collapsed": false,
        "_uuid": "ab51d2e300e204d4f396f155f86386a8d3b906fb",
        "_execution_state": "idle"
      },
      "execution_count": null,
      "outputs": [],
      "source": "### Thanks for reading. If you find some mistake or I made wrong understanding, a feedback is appreciate.",
      "cell_type": "markdown"
    }
  ]
}