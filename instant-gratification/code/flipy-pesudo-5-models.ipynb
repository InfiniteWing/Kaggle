{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier, RadiusNeighborsRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# two pre-trained csv file from https://www.kaggle.com/infinitewing/ensemble-v2?scriptVersionId=15845030\n",
    "oof = pd.read_csv('../input/oof_pred_v3.csv')\n",
    "oof_v5 = pd.read_csv('../input/oof_pred_v5.csv')\n",
    "test_preds = pd.read_csv('../input/test_pred_v3.csv')\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "original_target = train['target'].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698331699467533\n"
     ]
    }
   ],
   "source": [
    "oof['target_mean'] = oof['oof_qda']*0.23 + \\\n",
    "                        oof['oof_gmm']*0.23 + \\\n",
    "                        oof['oof_nusvc']*0.23 + \\\n",
    "                        oof['oof_log']*0.23 + \\\n",
    "                        oof_v5['oof_knn']*0.08\n",
    "print(roc_auc_score(original_target, oof['target_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(x,y,oof_x,test_x):\n",
    "    model = KNeighborsClassifier(19,p=1.9,n_jobs=-1)\n",
    "    model.fit(x,y)\n",
    "    oof = model.predict_proba(oof_x)\n",
    "    preds = model.predict_proba(test_x)\n",
    "    return oof, preds\n",
    "def qda_model(x,y,oof_x,test_x):\n",
    "    model = QuadraticDiscriminantAnalysis(0.1)\n",
    "    model.fit(x,y)\n",
    "    oof = model.predict_proba(oof_x)\n",
    "    pred = model.predict_proba(test_x)\n",
    "    return oof, pred\n",
    "def log_model(x,y,oof_x,test_x):\n",
    "    model = LogisticRegression(solver='liblinear',penalty='l2',C=0.001,tol=0.0001,random_state=0,max_iter=1000,n_jobs=-1)\n",
    "    model.fit(x,y)\n",
    "    oof = model.predict_proba(oof_x)\n",
    "    pred = model.predict_proba(test_x)\n",
    "    return oof, pred\n",
    "\n",
    "def nusvc_model(x,y,oof_x,test_x):\n",
    "    model = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.7, coef0=0.053)\n",
    "    model.fit(x,y)\n",
    "    oof = model.predict_proba(oof_x)\n",
    "    pred = model.predict_proba(test_x)\n",
    "    return oof, pred\n",
    "\n",
    "def gmm_model(x,y,oof_x,test_x):\n",
    "    def get_mean_cov(x,y):\n",
    "        model = GraphicalLasso()\n",
    "        ones = (y==1).astype(bool)\n",
    "        x2 = x[ones]\n",
    "        model.fit(x2)\n",
    "        p1 = model.precision_\n",
    "        m1 = model.location_\n",
    "        \n",
    "        onesb = (y==0).astype(bool)\n",
    "        x2b = x[onesb]\n",
    "        model.fit(x2b)\n",
    "        p2 = model.precision_\n",
    "        m2 = model.location_\n",
    "        \n",
    "        ms = np.stack([m1,m2])\n",
    "        ps = np.stack([p1,p2])\n",
    "        return ms,ps\n",
    "        \n",
    "    ms, ps = get_mean_cov(x,y)\n",
    "    model = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=250, n_init=1,means_init=ms, precisions_init=ps)\n",
    "    model.fit(np.concatenate([x,test_x],axis = 0))\n",
    "    #model.fit(x)\n",
    "    oof = model.predict_proba(oof_x)\n",
    "    pred = model.predict_proba(test_x)\n",
    "    \n",
    "    tmp = oof[:,0].copy()\n",
    "    oof[:,0] = oof[:,1]\n",
    "    oof[:,1] = tmp\n",
    "    \n",
    "    tmp = pred[:,0].copy()\n",
    "    pred[:,0] = pred[:,1]\n",
    "    pred[:,1] = tmp\n",
    "    \n",
    "    return oof, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 4)\n",
      "qda 0.3% acc: 0.9729475417548812\n",
      "log 0.2% acc: 0.9727915160647358\n",
      "nusvc 0.3% acc: 0.9720574491216694\n",
      "gmm 0.3% acc: 0.9743653321634973\n",
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "Totally has 162860 ~97.4% accuracy daya\n"
     ]
    }
   ],
   "source": [
    "gmm = oof['oof_gmm'].rank().values / len(oof['oof_gmm'])\n",
    "qda = oof['oof_qda'].rank().values / len(oof['oof_gmm'])\n",
    "nusvc = oof['oof_nusvc'].rank().values / len(oof['oof_gmm'])\n",
    "log = oof['oof_log'].rank().values / len(oof['oof_gmm'])\n",
    "\n",
    "models = [qda, log, nusvc, gmm]\n",
    "models_name = ['qda', 'log', 'nusvc', 'gmm']\n",
    "models_threshold = [0.3, 0.2, 0.3, 0.3]\n",
    "\n",
    "targets = oof['target'].copy().values\n",
    "new_preds = np.array([[-1 for _ in range(len(models))] for _ in range(len(targets))]).astype('float')\n",
    "print(new_preds.shape)\n",
    "for i, (model, name, threshold) in enumerate(zip(models, models_name, models_threshold)):\n",
    "    preds = model.copy().astype('float')\n",
    "    # 把符合比例的preds id 記錄下來，之後比較variance，沒有差異的話就加入flip的行列\n",
    "    # OOF的時候flip可以達到0.974x的acc，代表幾乎是正確的標籤\n",
    "    preds[preds > 1-threshold] = 1\n",
    "    preds[preds < threshold] = 0\n",
    "    new_preds[:,i] = preds.astype('float')\n",
    "    sure_idx = np.concatenate((np.where(preds==1)[0], np.where(preds==0)[0]))\n",
    "    acc = accuracy_score(targets[sure_idx], new_preds[sure_idx,i])\n",
    "    print('{} {}% acc: {}'.format(name, threshold, acc))\n",
    "use_idx = []\n",
    "use_preds = []\n",
    "for i in range(new_preds.shape[0]):  \n",
    "    use_preds.append(-1)\n",
    "    if(i%50000==0): print(i)\n",
    "    # 檢查不同模型是否對該預測點出現分歧，出現分歧者自然不加入flip的行列\n",
    "    values = []\n",
    "    for j in range(new_preds.shape[1]):\n",
    "        if(new_preds[i,j] == 0 or new_preds[i,j] == 1):\n",
    "            values.append(new_preds[i,j])\n",
    "    if(len(values) == 0): continue\n",
    "    if(np.std(np.array(values)) == 0 and len(values) > 1):\n",
    "        use_idx.append(i)\n",
    "        use_preds[i] = values[0]\n",
    "use_idx = np.array(use_idx)    \n",
    "use_preds = np.array(use_preds)    \n",
    "print('Totally has {} ~97.4% accuracy daya'.format(len(use_idx)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698331699467533\n",
      "0.9740390519464571\n"
     ]
    }
   ],
   "source": [
    "base_preds = oof['target_mean'].copy().values\n",
    "auc = roc_auc_score(original_target, base_preds)\n",
    "print(auc)\n",
    "base_preds[use_idx] = use_preds[use_idx]\n",
    "acc = accuracy_score(original_target[use_idx], base_preds[use_idx])\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these incorrect label seems to be flipped target, re-fix it!\n",
      "4228\n"
     ]
    }
   ],
   "source": [
    "print('these incorrect label seems to be flipped target, re-fix it!')\n",
    "not_match_idx = np.where(use_preds[use_idx] != targets[use_idx])[0]\n",
    "print(len(not_match_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof['target'][use_idx[not_match_idx]] = use_preds[use_idx[not_match_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn with flip-y auc: 0.92269\n",
      "knn original auc: 0.91923\n",
      "qda with flip-y auc: 0.967287\n",
      "qda original auc: 0.965618\n",
      "log with flip-y auc: 0.956718\n",
      "log original auc: 0.953721\n",
      "nusvc with flip-y auc: 0.966879\n",
      "nusvc original auc: 0.964883\n",
      "gmm with flip-y auc: 0.969061\n",
      "gmm original auc: 0.969059\n",
      "ensemble with flip-y auc: 0.970144\n"
     ]
    }
   ],
   "source": [
    "baseline_qda_preds = oof['oof_qda'].copy().values\n",
    "baseline_log_preds = oof['oof_log'].copy().values\n",
    "baseline_nusvc_preds = oof['oof_nusvc'].copy().values\n",
    "baseline_gmm_preds = oof['oof_gmm'].copy().values\n",
    "baseline_knn_preds = oof_v5['oof_knn'].copy().values\n",
    "targets = train['target'].copy().values\n",
    "# 將應該是錯誤的y labels 重新flip\n",
    "train['target'][use_idx[not_match_idx]] = use_preds[use_idx[not_match_idx]]\n",
    "cols = [c for c in train.columns if c not in ['id', 'target','wheezy-copper-turtle-magic']]\n",
    "\n",
    "m0 = knn_model\n",
    "m1 = qda_model\n",
    "m2 = log_model\n",
    "m3 = nusvc_model\n",
    "m4 = gmm_model\n",
    "models_baseline = [baseline_knn_preds,baseline_qda_preds,baseline_log_preds,baseline_nusvc_preds,baseline_gmm_preds]\n",
    "models = [('knn',m0), ('qda',m1), ('log',m2), ('nusvc',m3), ('gmm',m4)]\n",
    "oofs = np.zeros((len(oof),len(models)))\n",
    "preds = np.zeros((len(test),len(models)))\n",
    "ps_oofs = np.zeros((len(oof),len(models)))\n",
    "ps_preds = np.zeros((len(test),len(models)))\n",
    "for a, (model_name, model) in enumerate(models):\n",
    "    for i in (range(512)):\n",
    "        #if(i%50 == 0): print(i)\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i].copy()\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i].copy()\n",
    "        idx1 = train2.index\n",
    "        idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "        y = train2['target'].copy().values\n",
    "        \n",
    "        \n",
    "        if(model_name == 'log'):\n",
    "            poly = PolynomialFeatures(degree=2)\n",
    "            sc = StandardScaler()\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = poly.fit_transform(sc.fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols])))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        if(model_name == 'qda' or model_name == 'gmm' or model_name == 'knn'):\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = StandardScaler().fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols]))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "\n",
    "\n",
    "        if(model_name == 'nusvc'):\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=21, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(train3, y):\n",
    "            _oof, _pred = model(train3[train_index,:],            # x\n",
    "                                y[train_index],                   # y\n",
    "                                train3[test_index,:], test3)      # oof_x, test_x\n",
    "            oofs[idx1[test_index],a] = _oof[:,1]\n",
    "            preds[idx2,a] += _pred[:,1] / skf.n_splits\n",
    "    auc = roc_auc_score(original_target, oofs[:,a])\n",
    "    print('{} with flip-y auc: {}'.format(model_name, round(auc,6)))\n",
    "    auc = roc_auc_score(original_target, models_baseline[a])\n",
    "    print('{} original auc: {}'.format(model_name, round(auc,6)))\n",
    "auc = roc_auc_score(original_target, np.mean(oofs,axis=1))\n",
    "print('{} with flip-y auc: {}'.format('ensemble', round(auc,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1_preds = np.mean(preds, axis=1)\n",
    "# first one is knn\n",
    "step1_preds = preds[:,0]*0.08 + \\\n",
    "                 + preds[:,1]*0.23 + preds[:,2]*0.23 + preds[:,3]*0.23 + preds[:,4]*0.23\n",
    "test['target'] = step1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡重複剛才選要flip的步驟，找到合適的test preds label，因為他的accuracy有97.4%以上，所以非常適合！\n",
    "首先建立DataFrame，因為需要使用到.rank()\n",
    "models = [('knn',m0), ('qda',m1), ('log',m2), ('nusvc',m3), ('gmm',m4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "qda\n",
      "log\n",
      "nusvc\n",
      "gmm\n"
     ]
    }
   ],
   "source": [
    "preds_df = pd.DataFrame()\n",
    "for a, (model_name, model) in enumerate(models):\n",
    "    print(model_name)\n",
    "    preds_df['preds_{}'.format(model_name)] = preds[:,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm2 = preds_df['preds_gmm'].rank().values / len(preds_df['preds_gmm'])\n",
    "qda2 = preds_df['preds_qda'].rank().values / len(preds_df['preds_gmm'])\n",
    "nusvc2 = preds_df['preds_nusvc'].rank().values / len(preds_df['preds_gmm'])\n",
    "log2 = preds_df['preds_log'].rank().values / len(preds_df['preds_gmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 4)\n",
      "0\n",
      "50000\n",
      "100000\n",
      "Totally has 81422 ~97.4% accuracy data for pseudo labeling!!!\n"
     ]
    }
   ],
   "source": [
    "models = [qda2, log2, nusvc2, gmm2]\n",
    "models_name = ['qda', 'log', 'nusvc', 'gmm']\n",
    "models_threshold = [0.3, 0.2, 0.3, 0.3]\n",
    "\n",
    "new_preds2 = np.array([[-1 for _ in range(len(models))] for _ in range(len(nusvc2))]).astype('float')\n",
    "print(new_preds.shape)\n",
    "for i, (model, name, threshold) in enumerate(zip(models, models_name, models_threshold)):\n",
    "    preds = model.copy().astype('float')\n",
    "    # 把符合比例的preds id 記錄下來，之後比較variance，沒有差異的話就加入pseudo的行列\n",
    "    # OOF的時候可以達到0.974x的acc，代表幾乎是正確的標籤\n",
    "    preds[preds > 1-threshold] = 1\n",
    "    preds[preds < threshold] = 0\n",
    "    new_preds2[:,i] = preds.astype('float')\n",
    "    sure_idx = np.concatenate((np.where(preds==1)[0], np.where(preds==0)[0]))\n",
    "use_idx2 = []\n",
    "use_preds2 = []\n",
    "for i in range(new_preds2.shape[0]):  \n",
    "    use_preds2.append(-1)\n",
    "    if(i%50000==0): print(i)\n",
    "    # 檢查不同模型是否對該預測點出現分歧，出現分歧者自然不加入pseudo的行列\n",
    "    values = []\n",
    "    for j in range(new_preds2.shape[1]):\n",
    "        if(new_preds2[i,j] == 0 or new_preds2[i,j] == 1):\n",
    "            values.append(new_preds2[i,j])\n",
    "    if(len(values) == 0): continue\n",
    "    if(np.std(np.array(values)) == 0 and len(values) > 1):\n",
    "        use_idx2.append(i)\n",
    "        use_preds2[i] = values[0]\n",
    "use_idx2 = np.array(use_idx2)    \n",
    "use_preds2 = np.array(use_preds2)    \n",
    "print('Totally has {} ~97.4% accuracy data for pseudo labeling!!!'.format(len(use_idx2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   preds_knn     preds_qda  preds_log  preds_nusvc     preds_gmm  use_target  \\\n",
      "0   0.498747  9.999991e-01   0.571359     0.879075  9.999999e-01           1   \n",
      "1   0.488722  9.974835e-01   0.537612     0.881171  9.986900e-01          -1   \n",
      "2   0.533835  1.011638e-07   0.492571     0.093782  2.070371e-10           0   \n",
      "3   0.403509  1.481468e-01   0.469918     0.633640  4.578538e-03          -1   \n",
      "4   0.278195  4.960512e-01   0.454024     0.053372  4.776994e-02          -1   \n",
      "5   0.210526  1.893203e-08   0.266370     0.003395  1.371139e-10           0   \n",
      "6   0.150376  2.442548e-11   0.274422     0.001483  9.364499e-10           0   \n",
      "7   0.766917  9.999998e-01   0.655710     0.992062  1.000000e+00           1   \n",
      "8   0.453634  9.999268e-01   0.555846     0.760626  9.999940e-01           1   \n",
      "9   0.395990  1.108485e-02   0.463084     0.206428  2.951555e-04          -1   \n",
      "\n",
      "   useful  wheezy-copper-turtle-magic  \n",
      "0     1.0                         259  \n",
      "1     0.0                         252  \n",
      "2     1.0                         364  \n",
      "3     0.0                           0  \n",
      "4     0.0                         204  \n",
      "5     1.0                         260  \n",
      "6     1.0                         204  \n",
      "7     1.0                         466  \n",
      "8     1.0                         243  \n",
      "9     0.0                         448  \n"
     ]
    }
   ],
   "source": [
    "preds_df['use_target'] = use_preds2.astype('int32')\n",
    "preds_df['useful'] = np.zeros(len(use_preds2))\n",
    "preds_df['useful'][use_idx2] = 1\n",
    "preds_df['wheezy-copper-turtle-magic'] = test['wheezy-copper-turtle-magic'].copy().values\n",
    "print(preds_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-87a2cb12b961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m             _oof, _pred = model(train3[train_index,:],            # x\n\u001b[0;32m     56\u001b[0m                                 \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                   \u001b[1;31m# y\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                                 train3[test_index3,:], test3)      # oof_x, test_x\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mps_oofs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_oof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mps_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0m_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mskf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-41ff21d9c9a9>\u001b[0m in \u001b[0;36mknn_model\u001b[1;34m(x, y, oof_x, test_x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 delayed_query(\n\u001b[0;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             )\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\multiprocessing\\util.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[0;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[0;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining worker handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mworker_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m             \u001b[0mworker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# Terminate workers which haven't already finished.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infinitewing\\appdata\\local\\programs\\python\\python35\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m0 = knn_model\n",
    "m1 = qda_model\n",
    "m2 = log_model\n",
    "m3 = nusvc_model\n",
    "m4 = gmm_model\n",
    "models_baseline = [baseline_knn_preds,baseline_qda_preds,baseline_log_preds,baseline_nusvc_preds,baseline_gmm_preds]\n",
    "models = [('knn',m0), ('qda',m1), ('log',m2), ('nusvc',m3), ('gmm',m4)]\n",
    "# pseudo label\n",
    "for a, (model_name, model) in enumerate(models):\n",
    "    for i in (range(512)):\n",
    "        train2 = train[train['wheezy-copper-turtle-magic']==i].copy()\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i].copy()\n",
    "        preds_df2 = preds_df[preds_df['wheezy-copper-turtle-magic']==i].copy()\n",
    "        idx1 = train2.index\n",
    "        idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "        test2.reset_index(drop=True,inplace=True)\n",
    "        preds_df2.reset_index(drop=True,inplace=True)\n",
    "        y = train2['target'].copy().values\n",
    "        test_y = preds_df2['use_target'].copy().values\n",
    "        \n",
    "        #找到有用的idx，這裡是[0 ~ length]\n",
    "        pesudo_useful_idx = np.where(preds_df2['useful']==1)[0]\n",
    "        \n",
    "        if(model_name == 'log'):\n",
    "            poly = PolynomialFeatures(degree=2)\n",
    "            sc = StandardScaler()\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = poly.fit_transform(sc.fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols])))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        if(model_name == 'qda' or model_name == 'gmm' or model_name == 'knn'):\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = StandardScaler().fit_transform(VarianceThreshold(threshold=2).fit_transform(data[cols]))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "\n",
    "\n",
    "        if(model_name == 'nusvc'):\n",
    "            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "            data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n",
    "            train3 = data2[:train2.shape[0]]\n",
    "            test3 = data2[train2.shape[0]:]\n",
    "            \n",
    "        # 如果有可以用的pseudo label,將其加入train data中\n",
    "        # test_y因為剛才已經有做過0-1二元化，所以直接加入\n",
    "        if(len(pesudo_useful_idx) > 0):\n",
    "            train3 = np.concatenate((train3, test3[pesudo_useful_idx,:]))\n",
    "            y = np.concatenate((y,test_y[pesudo_useful_idx]))\n",
    "            \n",
    "        skf = StratifiedKFold(n_splits=21, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(train3, y):\n",
    "            test_index3 = test_index[test_index<len(train2)]      # ignore pseudo in oof\n",
    "            _oof, _pred = model(train3[train_index,:],            # x\n",
    "                                y[train_index],                   # y\n",
    "                                train3[test_index3,:], test3)      # oof_x, test_x\n",
    "            ps_oofs[idx1[test_index3],a] = _oof[:,1]\n",
    "            ps_preds[idx2,a] += _pred[:,1] / skf.n_splits\n",
    "    auc = roc_auc_score(original_target, ps_oofs[:,a])\n",
    "    print('{} with flip-y + pseudo label auc: {}'.format(model_name, round(auc,6)))\n",
    "    auc = roc_auc_score(original_target, models_baseline[a])\n",
    "    print('{} original auc: {}'.format(model_name, round(auc,6)))\n",
    "auc = roc_auc_score(original_target, np.mean(ps_oofs,axis=1))\n",
    "print('{} with flip-y + pseudo label auc: {}'.format('ensemble', round(auc,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ps_oof = ps_oofs[:,0]*0.08 + \\\n",
    "                 + ps_oofs[:,1]*0.23 + ps_oofs[:,2]*0.23 + ps_oofs[:,3]*0.23 + ps_oofs[:,4]*0.23\n",
    "auc = roc_auc_score(original_target, best_ps_oof)\n",
    "print('{} with flip-y + pseudo label auc: {}'.format('best weight ensemble', round(auc,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = ps_preds[:,0]*0.08 + \\\n",
    "                 + ps_preds[:,1]*0.23 + ps_preds[:,2]*0.23 + ps_preds[:,3]*0.23 + ps_preds[:,4]*0.23\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['target'] = final_preds\n",
    "sub.to_csv('submission_flipy_pseudo_5models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm(x, y, oof_x, test_x):\n",
    "    lgb_params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'application': 'binary',\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 64,\n",
    "        'verbosity': -1,\n",
    "        'metric': 'auc'\n",
    "    }\n",
    "    d_train = lgb.Dataset(x, label=y)\n",
    "    model = lgb.train(lgb_params, train_set=d_train, num_boost_round=330, verbose_eval=1000)\n",
    "\n",
    "    oof = model.predict(oof_x)\n",
    "    preds = model.predict(test_x)\n",
    "    return oof, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "oof_df['target'] = train['target'].copy().values\n",
    "for a, (model_name, model) in enumerate(models):\n",
    "    oof_df['{}'.format(model_name)] = ps_oofs[:,a]\n",
    "    test_df['{}'.format(model_name)] = ps_preds[:,a]\n",
    "print(oof_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = [c for c in oof_df.columns if c not in ['id', 'target','wheezy-copper-turtle-magic']]\n",
    "trainX = oof_df[cols2].values\n",
    "y = oof_df['target'].values\n",
    "testX = test_df[cols2].values\n",
    "stack_oofs = np.zeros(len(trainX))\n",
    "stack_preds = np.zeros(len(testX))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=11, random_state=3228, shuffle=True)\n",
    "for train_index, test_index in skf.split(trainX, y):\n",
    "    _oof, _preds = lgbm(trainX[train_index,:],                # x\n",
    "                            y[train_index],                   # y\n",
    "                            trainX[test_index,:], testX)      # oof_x, test_x\n",
    "    stack_oofs[test_index] = _oof\n",
    "    stack_preds += _preds / skf.n_splits\n",
    "auc = roc_auc_score(original_target, stack_oofs)\n",
    "print('{} oof auc: {}'.format('final stacking', round(auc,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "sub['target'] = stack_preds\n",
    "sub.to_csv('submission_flipy_pseudo_stacking_5models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
